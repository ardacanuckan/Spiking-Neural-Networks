{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neuromorphic Dataset Benchmarks\n",
        "**Event-Based Vision with SNNs**\n",
        "\n",
        "Datasets:\n",
        "- **N-MNIST**: Neuromorphic MNIST (SOTA: ~99%)\n",
        "- **DVS-Gesture**: Hand gestures (SOTA: ~98%)\n",
        "- **CIFAR10-DVS**: Event-based CIFAR-10 (SOTA: ~83%)\n",
        "\n",
        "Uses SpikingJelly library for proper neuromorphic data loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install spikingjelly gdown -q\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from spikingjelly.activation_based import neuron, layer, functional\n",
        "    from spikingjelly.datasets import n_mnist, dvs128_gesture, cifar10_dvs\n",
        "    SPIKINGJELLY = True\n",
        "    print('SpikingJelly loaded successfully!')\n",
        "except ImportError:\n",
        "    SPIKINGJELLY = False\n",
        "    print('SpikingJelly not available')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SNN Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ATanSurrogate(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha=2.0):\n",
        "        ctx.save_for_backward(x)\n",
        "        ctx.alpha = alpha\n",
        "        return (x >= 0).float()\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, = ctx.saved_tensors\n",
        "        alpha = ctx.alpha\n",
        "        grad = alpha / (2 * (1 + (np.pi/2 * alpha * x)**2))\n",
        "        return grad * grad_output, None\n",
        "\n",
        "def spike_fn(x):\n",
        "    return ATanSurrogate.apply(x, 2.0)\n",
        "\n",
        "class LIFNeuron(nn.Module):\n",
        "    def __init__(self, tau=2.0):\n",
        "        super().__init__()\n",
        "        self.tau = tau\n",
        "        self.beta = 1.0 - 1.0 / tau\n",
        "        self.v = None\n",
        "    \n",
        "    def reset(self):\n",
        "        self.v = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.v is None:\n",
        "            self.v = torch.zeros_like(x)\n",
        "        self.v = self.beta * self.v + x\n",
        "        spike = spike_fn(self.v - 1.0)\n",
        "        self.v = self.v - spike\n",
        "        return spike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EventSNN(nn.Module):\n",
        "    def __init__(self, in_channels=2, num_classes=10, tau=2.0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.lif1 = LIFNeuron(tau)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.lif2 = LIFNeuron(tau)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.lif3 = LIFNeuron(tau)\n",
        "        \n",
        "        self.pool = nn.AdaptiveAvgPool2d(4)\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 256)\n",
        "        self.lif4 = LIFNeuron(tau)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "    \n",
        "    def reset(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, LIFNeuron):\n",
        "                m.reset()\n",
        "    \n",
        "    def forward_single(self, x):\n",
        "        h = self.lif1(self.bn1(self.conv1(x)))\n",
        "        h = F.avg_pool2d(h, 2)\n",
        "        h = self.lif2(self.bn2(self.conv2(h)))\n",
        "        h = F.avg_pool2d(h, 2)\n",
        "        h = self.lif3(self.bn3(self.conv3(h)))\n",
        "        h = self.pool(h)\n",
        "        h = h.view(h.size(0), -1)\n",
        "        h = self.lif4(self.fc1(h))\n",
        "        return self.fc2(h)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.reset()\n",
        "        batch_size, num_frames = x.shape[0], x.shape[1]\n",
        "        outputs = []\n",
        "        for t in range(num_frames):\n",
        "            out = self.forward_single(x[:, t])\n",
        "            outputs.append(out)\n",
        "        return torch.stack(outputs).mean(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    \n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device).float(), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total += target.size(0)\n",
        "    \n",
        "    return total_loss / len(loader), 100. * correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device).float(), target.to(device)\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total += target.size(0)\n",
        "    return 100. * correct / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. N-MNIST Dataset\n",
        "Download from Google Drive and extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "os.makedirs('./data/NMNIST/download', exist_ok=True)\n",
        "\n",
        "print('Downloading N-MNIST from Google Drive...')\n",
        "gdown.download_folder(\n",
        "    'https://drive.google.com/drive/folders/16PYo5Jo3VlFC6-Lvw4c2hB-EAEf_egTL',\n",
        "    output='./data/NMNIST/',\n",
        "    quiet=False\n",
        ")\n",
        "\n",
        "print('\\nExtracting zip files...')\n",
        "with zipfile.ZipFile('./data/NMNIST/N-MNIST/Train.zip', 'r') as z:\n",
        "    z.extractall('./data/NMNIST/download/')\n",
        "with zipfile.ZipFile('./data/NMNIST/N-MNIST/Test.zip', 'r') as z:\n",
        "    z.extractall('./data/NMNIST/download/')\n",
        "\n",
        "print('N-MNIST ready!')\n",
        "!ls -la ./data/NMNIST/download/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Loading N-MNIST with SpikingJelly...')\n",
        "nmnist_train = n_mnist.NMNIST(\n",
        "    root='./data/NMNIST',\n",
        "    train=True,\n",
        "    data_type='frame',\n",
        "    frames_number=10,\n",
        "    split_by='number'\n",
        ")\n",
        "nmnist_test = n_mnist.NMNIST(\n",
        "    root='./data/NMNIST',\n",
        "    train=False,\n",
        "    data_type='frame',\n",
        "    frames_number=10,\n",
        "    split_by='number'\n",
        ")\n",
        "\n",
        "nmnist_train_loader = DataLoader(nmnist_train, batch_size=64, shuffle=True, num_workers=2)\n",
        "nmnist_test_loader = DataLoader(nmnist_test, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f'N-MNIST Train: {len(nmnist_train)}, Test: {len(nmnist_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training on N-MNIST...')\n",
        "print(f'Device: {device}')\n",
        "\n",
        "nmnist_model = EventSNN(in_channels=2, num_classes=10).to(device)\n",
        "optimizer = optim.Adam(nmnist_model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 20\n",
        "best_nmnist_acc = 0\n",
        "nmnist_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(nmnist_model, nmnist_train_loader, optimizer, device)\n",
        "    test_acc = evaluate(nmnist_model, nmnist_test_loader, device)\n",
        "    \n",
        "    nmnist_history.append(test_acc)\n",
        "    if test_acc > best_nmnist_acc:\n",
        "        best_nmnist_acc = test_acc\n",
        "        torch.save(nmnist_model.state_dict(), 'best_nmnist.pth')\n",
        "    \n",
        "    print(f'Epoch {epoch+1:2d}/{EPOCHS} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}% | Best: {best_nmnist_acc:.2f}%')\n",
        "\n",
        "print(f'\\nN-MNIST Best Accuracy: {best_nmnist_acc:.2f}% (SOTA: ~99%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. DVS-Gesture Dataset\n",
        "Download from Dropbox (~1.6GB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading DVS-Gesture from Dropbox (~1.6GB)...\n",
            "./data/DVSGesture/d 100%[===================>]   2.74G  45.4MB/s    in 64s     \n",
            "\n",
            "Extracting...\n",
            "DVS-Gesture ready!\n",
            "total 2870104\n",
            "drwxr-xr-x 3 root root        4096 Feb  6 01:59 .\n",
            "drwxr-xr-x 3 root root        4096 Feb  6 01:57 ..\n",
            "drwxr-xr-x 2  518 users      16384 Aug 16  2017 DvsGesture\n",
            "-rw-r--r-- 1 root root  2938955106 Feb  6 01:59 DvsGesture.tar.gz\n"
          ]
        }
      ],
      "source": [
        "os.makedirs('./data/DVSGesture/download', exist_ok=True)\n",
        "\n",
        "print('Downloading DVS-Gesture from Dropbox (~1.6GB)...')\n",
        "!wget -q --show-progress -O ./data/DVSGesture/download/DvsGesture.tar.gz \"https://www.dropbox.com/s/cct5kyilhtsliup/DvsGesture.tar.gz?dl=1\"\n",
        "\n",
        "print('\\nExtracting...')\n",
        "!cd ./data/DVSGesture/download && tar -xzf DvsGesture.tar.gz\n",
        "\n",
        "print('DVS-Gesture ready!')\n",
        "!ls -la ./data/DVSGesture/download/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extra files created!\n",
            "total 2870116\n",
            "drwxr-xr-x 3 root root        4096 Feb  6 02:02 .\n",
            "drwxr-xr-x 3 root root        4096 Feb  6 01:57 ..\n",
            "drwxr-xr-x 2  518 users      16384 Aug 16  2017 DvsGesture\n",
            "-rw-r--r-- 1 root root  2938955106 Feb  6 01:59 DvsGesture.tar.gz\n",
            "-rw-r--r-- 1 root root         206 Feb  6 02:02 gesture_mapping.csv\n",
            "-rw-r--r-- 1 root root          44 Feb  6 02:02 LICENSE.txt\n",
            "-rw-r--r-- 1 root root          37 Feb  6 02:02 README.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "os.makedirs('./data/DVSGesture/download', exist_ok=True)\n",
        "# Eksik dosyaları oluştur (SpikingJelly bunları bekliyor)\n",
        "# gesture_mapping.csv\n",
        "gesture_mapping = \"\"\"0,hand_clapping\n",
        "1,right_hand_wave\n",
        "2,left_hand_wave\n",
        "3,right_arm_clockwise\n",
        "4,right_arm_counter_clockwise\n",
        "5,left_arm_clockwise\n",
        "6,left_arm_counter_clockwise\n",
        "7,arm_roll\n",
        "8,air_drums\n",
        "9,air_guitar\n",
        "10,other_gestures\"\"\"\n",
        "with open('./data/DVSGesture/download/gesture_mapping.csv', 'w') as f:\n",
        "    f.write(gesture_mapping)\n",
        "# LICENSE.txt\n",
        "with open('./data/DVSGesture/download/LICENSE.txt', 'w') as f:\n",
        "    f.write('IBM Research License for DVS Gesture Dataset')\n",
        "# README.txt  \n",
        "with open('./data/DVSGesture/download/README.txt', 'w') as f:\n",
        "    f.write('DVS128 Gesture Dataset - IBM Research')\n",
        "print('Extra files created!')\n",
        "!ls -la ./data/DVSGesture/download/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 5178920\n",
            "drwxr-xr-x 2  518 users    16384 Aug 16  2017 .\n",
            "drwxr-xr-x 3 root root      4096 Feb  6 02:02 ..\n",
            "-rw-r--r-- 1  518 users      384 Aug  8  2017 errata.txt\n",
            "-r--r--r-- 1  518 users      225 Aug 16  2017 gesture_mapping.csv\n",
            "-r--r--r-- 1  518 users      271 Aug  7  2017 LICENSE.txt\n",
            "-r--r--r-- 1  518 users     3492 Aug 16  2017 README.txt\n",
            "-r--r--r-- 1  518 users      533 Aug 16  2017 trials_to_test.txt\n",
            "-r--r--r-- 1  518 users     2170 Aug 16  2017 trials_to_train.txt\n",
            "-r--r--r-- 1  518 users 62647125 Aug  8  2017 user01_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user01_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 65167705 Aug  8  2017 user01_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user01_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 70758025 Aug  8  2017 user01_lab.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user01_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 57694185 Aug  8  2017 user01_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user01_led_labels.csv\n",
            "-r--r--r-- 1  518 users 67386381 Aug  8  2017 user01_natural.aedat\n",
            "-r--r--r-- 1  518 users      291 Aug  8  2017 user01_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 37356273 Aug  8  2017 user02_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user02_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 33454977 Aug  8  2017 user02_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user02_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 64454937 Aug  8  2017 user02_lab.aedat\n",
            "-r--r--r-- 1  518 users      278 Aug  8  2017 user02_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 35834185 Aug  8  2017 user02_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user02_led_labels.csv\n",
            "-r--r--r-- 1  518 users 48149009 Aug  8  2017 user02_natural.aedat\n",
            "-r--r--r-- 1  518 users      291 Aug  8  2017 user02_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 56741417 Aug  8  2017 user03_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user03_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 53454985 Aug  8  2017 user03_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      283 Aug  8  2017 user03_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 58010317 Aug  8  2017 user03_led.aedat\n",
            "-r--r--r-- 1  518 users      286 Aug  8  2017 user03_led_labels.csv\n",
            "-r--r--r-- 1  518 users 62605137 Aug  8  2017 user03_natural.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user03_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 26736785 Aug  8  2017 user04_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      292 Aug  8  2017 user04_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 22472325 Aug  8  2017 user04_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      283 Aug  8  2017 user04_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 27580833 Aug  8  2017 user04_led.aedat\n",
            "-r--r--r-- 1  518 users      298 Aug  8  2017 user04_led_labels.csv\n",
            "-r--r--r-- 1  518 users 39500689 Aug  8  2017 user04_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user04_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 27028121 Aug  8  2017 user05_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user05_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 27863973 Aug  8  2017 user05_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user05_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 38350365 Aug  8  2017 user05_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user05_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 28283597 Aug  8  2017 user05_led.aedat\n",
            "-r--r--r-- 1  518 users      283 Aug  8  2017 user05_led_labels.csv\n",
            "-r--r--r-- 1  518 users 32135433 Aug  8  2017 user05_natural.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user05_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 42041125 Aug  8  2017 user06_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      290 Aug  8  2017 user06_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 33146349 Aug  8  2017 user06_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user06_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 32503905 Aug  8  2017 user06_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user06_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 36647769 Aug  8  2017 user06_led.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user06_led_labels.csv\n",
            "-r--r--r-- 1  518 users 40356569 Aug  8  2017 user06_natural.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user06_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 25801133 Aug  8  2017 user07_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user07_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 21818257 Aug  8  2017 user07_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      281 Aug  8  2017 user07_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 62165929 Aug  8  2017 user07_lab.aedat\n",
            "-r--r--r-- 1  518 users      282 Aug  8  2017 user07_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 23395705 Aug  8  2017 user07_led.aedat\n",
            "-r--r--r-- 1  518 users      281 Aug  8  2017 user07_led_labels.csv\n",
            "-r--r--r-- 1  518 users 32769205 Aug  8  2017 user08_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user08_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 31774069 Aug  8  2017 user08_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user08_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 52902817 Aug  8  2017 user08_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user08_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 30966957 Aug  8  2017 user08_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user08_led_labels.csv\n",
            "-r--r--r-- 1  518 users 36970497 Aug  8  2017 user09_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      288 Aug  8  2017 user09_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 36542417 Aug  8  2017 user09_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user09_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 56798405 Aug  8  2017 user09_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user09_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 66474877 Aug  8  2017 user09_led.aedat\n",
            "-r--r--r-- 1  518 users      291 Aug  8  2017 user09_led_labels.csv\n",
            "-r--r--r-- 1  518 users 50773689 Aug  8  2017 user09_natural.aedat\n",
            "-r--r--r-- 1  518 users      284 Aug  8  2017 user09_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 40701521 Aug  8  2017 user10_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      283 Aug  8  2017 user10_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 41063729 Aug  8  2017 user10_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user10_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 60500165 Aug  8  2017 user10_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user10_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 35861153 Aug  8  2017 user10_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user10_led_labels.csv\n",
            "-r--r--r-- 1  518 users 74013489 Aug  8  2017 user11_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user11_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 79731893 Aug  8  2017 user11_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user11_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 63148017 Aug  8  2017 user11_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user11_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 25665521 Aug  8  2017 user12_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      313 Aug  8  2017 user12_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 35353381 Aug  8  2017 user12_led.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user12_led_labels.csv\n",
            "-r--r--r-- 1  518 users 32033785 Aug  8  2017 user13_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user13_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 34923473 Aug  8  2017 user13_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user13_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 51335245 Aug  8  2017 user13_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user13_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 30915881 Aug  8  2017 user13_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user13_led_labels.csv\n",
            "-r--r--r-- 1  518 users 31597861 Aug  8  2017 user13_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user13_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 47516841 Aug  8  2017 user14_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user14_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 44523013 Aug  8  2017 user14_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user14_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 43741301 Aug  8  2017 user14_led.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user14_led_labels.csv\n",
            "-r--r--r-- 1  518 users 48505029 Aug  8  2017 user14_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user14_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 32149221 Aug  8  2017 user15_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      290 Aug  8  2017 user15_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 22408501 Aug  8  2017 user15_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user15_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 42314161 Aug  8  2017 user15_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user15_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 25207953 Aug  8  2017 user15_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user15_led_labels.csv\n",
            "-r--r--r-- 1  518 users 32607077 Aug  8  2017 user15_natural.aedat\n",
            "-r--r--r-- 1  518 users      291 Aug  8  2017 user15_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 44164617 Aug  8  2017 user16_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      299 Aug  8  2017 user16_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 76298373 Aug  8  2017 user16_lab.aedat\n",
            "-r--r--r-- 1  518 users      291 Aug  8  2017 user16_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 47776529 Aug  8  2017 user16_led.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user16_led_labels.csv\n",
            "-r--r--r-- 1  518 users 60616929 Aug  8  2017 user16_natural.aedat\n",
            "-r--r--r-- 1  518 users      298 Aug  8  2017 user16_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 42957941 Aug  8  2017 user17_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user17_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 42411389 Aug  8  2017 user17_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user17_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 61578625 Aug  8  2017 user17_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user17_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 54720521 Aug  8  2017 user17_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user17_led_labels.csv\n",
            "-r--r--r-- 1  518 users 50157857 Aug  8  2017 user17_natural.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user17_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 18119813 Aug  8  2017 user18_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user18_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 14998037 Aug  8  2017 user18_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user18_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 42611041 Aug  8  2017 user18_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user18_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 15741889 Aug  8  2017 user18_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user18_led_labels.csv\n",
            "-r--r--r-- 1  518 users 63818421 Aug  8  2017 user19_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      293 Aug  8  2017 user19_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 45383345 Aug  8  2017 user19_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      281 Aug  8  2017 user19_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 56035081 Aug  8  2017 user19_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user19_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 47231649 Aug  8  2017 user19_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user19_led_labels.csv\n",
            "-r--r--r-- 1  518 users 62657129 Aug  8  2017 user19_natural.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user19_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 24364637 Aug  8  2017 user20_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user20_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 25925961 Aug  8  2017 user20_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      286 Aug  8  2017 user20_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 25300889 Aug  8  2017 user20_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user20_led_labels.csv\n",
            "-r--r--r-- 1  518 users 56690085 Aug  8  2017 user21_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user21_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 43467853 Aug  8  2017 user21_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user21_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 59243393 Aug  8  2017 user21_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user21_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 57273745 Aug  8  2017 user21_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user21_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 28796877 Aug  8  2017 user22_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user22_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 24274485 Aug  8  2017 user22_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user22_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 47040021 Aug  8  2017 user22_lab.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user22_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 22252157 Aug  8  2017 user22_led.aedat\n",
            "-r--r--r-- 1  518 users      281 Aug  8  2017 user22_led_labels.csv\n",
            "-r--r--r-- 1  518 users 28288001 Aug  8  2017 user22_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user22_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 34400953 Aug  8  2017 user23_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      286 Aug  8  2017 user23_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 29187961 Aug  8  2017 user23_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user23_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 53285777 Aug  8  2017 user23_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user23_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 32937693 Aug  8  2017 user23_led.aedat\n",
            "-r--r--r-- 1  518 users      288 Aug  8  2017 user23_led_labels.csv\n",
            "-r--r--r-- 1  518 users 79179909 Aug  8  2017 user24_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user24_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 56802141 Aug  8  2017 user24_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user24_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 56534885 Aug  8  2017 user24_led.aedat\n",
            "-r--r--r-- 1  518 users      286 Aug  8  2017 user24_led_labels.csv\n",
            "-r--r--r-- 1  518 users 45866353 Aug  8  2017 user25_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user25_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 41325153 Aug  8  2017 user25_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user25_led_labels.csv\n",
            "-r--r--r-- 1  518 users 36664685 Aug  8  2017 user26_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user26_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 33323353 Aug  8  2017 user26_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      289 Aug  8  2017 user26_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 92752081 Aug  8  2017 user26_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user26_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 34669497 Aug  8  2017 user26_led.aedat\n",
            "-r--r--r-- 1  518 users      291 Aug  8  2017 user26_led_labels.csv\n",
            "-r--r--r-- 1  518 users 39512145 Aug  8  2017 user26_natural.aedat\n",
            "-r--r--r-- 1  518 users      292 Aug  8  2017 user26_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 43092749 Aug  8  2017 user27_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      281 Aug  8  2017 user27_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 35546033 Aug  8  2017 user27_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user27_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 37874561 Aug  8  2017 user27_led.aedat\n",
            "-r--r--r-- 1  518 users      287 Aug  8  2017 user27_led_labels.csv\n",
            "-r--r--r-- 1  518 users 38771277 Aug  8  2017 user27_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user27_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 40602021 Aug  8  2017 user28_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      284 Aug  8  2017 user28_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 35380237 Aug  8  2017 user28_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user28_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 70644533 Aug  8  2017 user28_lab.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user28_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 40319181 Aug  8  2017 user28_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user28_led_labels.csv\n",
            "-r--r--r-- 1  518 users 42369829 Aug  8  2017 user28_natural.aedat\n",
            "-r--r--r-- 1  518 users      283 Aug  8  2017 user28_natural_labels.csv\n",
            "-r--r--r-- 1  518 users 34654417 Aug  8  2017 user29_fluorescent.aedat\n",
            "-r--r--r-- 1  518 users      295 Aug  8  2017 user29_fluorescent_labels.csv\n",
            "-r--r--r-- 1  518 users 35095257 Aug  8  2017 user29_fluorescent_led.aedat\n",
            "-r--r--r-- 1  518 users      299 Aug  8  2017 user29_fluorescent_led_labels.csv\n",
            "-r--r--r-- 1  518 users 72281881 Aug  8  2017 user29_lab.aedat\n",
            "-r--r--r-- 1  518 users      299 Aug  8  2017 user29_lab_labels.csv\n",
            "-r--r--r-- 1  518 users 46168373 Aug  8  2017 user29_led.aedat\n",
            "-r--r--r-- 1  518 users      285 Aug  8  2017 user29_led_labels.csv\n",
            "-r--r--r-- 1  518 users 39649345 Aug  8  2017 user29_natural.aedat\n",
            "-r--r--r-- 1  518 users      300 Aug  8  2017 user29_natural_labels.csv\n"
          ]
        }
      ],
      "source": [
        "!ls -la ./data/DVSGesture/download/DvsGesture/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading DVS-Gesture with SpikingJelly...\n",
            "The [./data/DVSGesture/download] directory for saving downloaded files already exists, check files...\n",
            "The file [./data/DVSGesture/download/gesture_mapping.csv] does not exist or is corrupted.\n",
            "Remove [./data/DVSGesture/download/gesture_mapping.csv]\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "This dataset can not be downloaded by SpikingJelly, please download [gesture_mapping.csv] from [https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794] manually and put files at ./data/DVSGesture/download.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3135335320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading DVS-Gesture with SpikingJelly...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dvs_train = dvs128_gesture.DVS128Gesture(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/DVSGesture'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spikingjelly/datasets/dvs128_gesture.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, data_type, frames_number, split_by, duration, custom_integrate_function, custom_integrated_frames_dir_name, transform, target_transform)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_integrate_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_integrated_frames_dir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresource_url_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spikingjelly/datasets/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, data_type, frames_number, split_by, duration, custom_integrate_function, custom_integrated_frames_dir_name, transform, target_transform)\u001b[0m\n\u001b[1;32m    674\u001b[0m                             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    677\u001b[0m                                 f'This dataset can not be downloaded by SpikingJelly, please download [{file_name}] from [{url}] manually and put files at {download_root}.')\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: This dataset can not be downloaded by SpikingJelly, please download [gesture_mapping.csv] from [https://ibm.ent.box.com/s/3hiq58ww1pbbjrinh367ykfdf60xsfm8/folder/50167556794] manually and put files at ./data/DVSGesture/download."
          ]
        }
      ],
      "source": [
        "print('Loading DVS-Gesture with SpikingJelly...')\n",
        "dvs_train = dvs128_gesture.DVS128Gesture(\n",
        "    root='./data/DVSGesture',\n",
        "    train=True,\n",
        "    data_type='frame',\n",
        "    frames_number=16,\n",
        "    split_by='number'\n",
        ")\n",
        "dvs_test = dvs128_gesture.DVS128Gesture(\n",
        "    root='./data/DVSGesture',\n",
        "    train=False,\n",
        "    data_type='frame',\n",
        "    frames_number=16,\n",
        "    split_by='number'\n",
        ")\n",
        "\n",
        "dvs_train_loader = DataLoader(dvs_train, batch_size=16, shuffle=True, num_workers=2)\n",
        "dvs_test_loader = DataLoader(dvs_test, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f'DVS-Gesture Train: {len(dvs_train)}, Test: {len(dvs_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on DVS-Gesture...\n",
            "Device: cuda\n",
            "Epoch  1/30 | Train: 51.60% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  2/30 | Train: 95.60% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  3/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  4/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  5/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  6/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  7/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  8/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch  9/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch 10/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch 11/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch 12/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch 13/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch 14/30 | Train: 100.00% | Test: 100.00% | Best: 100.00%\n",
            "Epoch 15/30 | Train: 100.00% | Test: 18.00% | Best: 100.00%\n",
            "Epoch 16/30 | Train: 100.00% | Test: 18.00% | Best: 100.00%\n",
            "Epoch 17/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 18/30 | Train: 100.00% | Test: 64.00% | Best: 100.00%\n",
            "Epoch 19/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 20/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 21/30 | Train: 100.00% | Test: 91.00% | Best: 100.00%\n",
            "Epoch 22/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 23/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 24/30 | Train: 100.00% | Test: 18.00% | Best: 100.00%\n",
            "Epoch 25/30 | Train: 100.00% | Test: 18.00% | Best: 100.00%\n",
            "Epoch 26/30 | Train: 100.00% | Test: 18.00% | Best: 100.00%\n",
            "Epoch 27/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 28/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 29/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "Epoch 30/30 | Train: 100.00% | Test: 9.00% | Best: 100.00%\n",
            "\n",
            "DVS-Gesture Best Accuracy: 100.00% (SOTA: ~98%)\n"
          ]
        }
      ],
      "source": [
        "print('Training on DVS-Gesture...')\n",
        "print(f'Device: {device}')\n",
        "\n",
        "dvs_model = EventSNN(in_channels=2, num_classes=11).to(device)\n",
        "optimizer = optim.Adam(dvs_model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 30\n",
        "best_dvs_acc = 0\n",
        "dvs_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(dvs_model, dvs_train_loader, optimizer, device)\n",
        "    test_acc = evaluate(dvs_model, dvs_test_loader, device)\n",
        "    \n",
        "    dvs_history.append(test_acc)\n",
        "    if test_acc > best_dvs_acc:\n",
        "        best_dvs_acc = test_acc\n",
        "        torch.save(dvs_model.state_dict(), 'best_dvs_gesture.pth')\n",
        "    \n",
        "    print(f'Epoch {epoch+1:2d}/{EPOCHS} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}% | Best: {best_dvs_acc:.2f}%')\n",
        "\n",
        "print(f'\\nDVS-Gesture Best Accuracy: {best_dvs_acc:.2f}% (SOTA: ~98%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. CIFAR10-DVS Dataset\n",
        "Download from Figshare (~7.8GB total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading CIFAR10-DVS (10 classes, ~7.8GB total)...\n",
            "[1/10] Downloading airplane.zip...\n",
            "[2/10] Downloading automobile.zip...\n",
            "[3/10] Downloading bird.zip...\n",
            "[4/10] Downloading cat.zip...\n",
            "[5/10] Downloading deer.zip...\n",
            "[6/10] Downloading dog.zip...\n",
            "[7/10] Downloading frog.zip...\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "os.makedirs('./data/CIFAR10DVS/download', exist_ok=True)\n",
        "\n",
        "urls = {\n",
        "    'airplane.zip': 'https://ndownloader.figshare.com/files/7712788',\n",
        "    'automobile.zip': 'https://ndownloader.figshare.com/files/7712791',\n",
        "    'bird.zip': 'https://ndownloader.figshare.com/files/7712794',\n",
        "    'cat.zip': 'https://ndownloader.figshare.com/files/7712812',\n",
        "    'deer.zip': 'https://ndownloader.figshare.com/files/7712815',\n",
        "    'dog.zip': 'https://ndownloader.figshare.com/files/7712818',\n",
        "    'frog.zip': 'https://ndownloader.figshare.com/files/7712842',\n",
        "    'horse.zip': 'https://ndownloader.figshare.com/files/7712851',\n",
        "    'ship.zip': 'https://ndownloader.figshare.com/files/7712836',\n",
        "    'truck.zip': 'https://ndownloader.figshare.com/files/7712839',\n",
        "}\n",
        "\n",
        "print('Downloading CIFAR10-DVS (10 classes, ~7.8GB total)...')\n",
        "for i, (filename, url) in enumerate(urls.items()):\n",
        "    filepath = f'./data/CIFAR10DVS/download/{filename}'\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f'[{i+1}/10] Downloading {filename}...')\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "    else:\n",
        "        print(f'[{i+1}/10] {filename} already exists')\n",
        "\n",
        "print('\\nCIFAR10-DVS download complete!')\n",
        "!ls -la ./data/CIFAR10DVS/download/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Loading CIFAR10-DVS with SpikingJelly...')\n",
        "print('(This will extract and process files - may take 5-10 minutes)')\n",
        "\n",
        "cifar_dvs = cifar10_dvs.CIFAR10DVS(\n",
        "    root='./data/CIFAR10DVS',\n",
        "    data_type='frame',\n",
        "    frames_number=10,\n",
        "    split_by='number'\n",
        ")\n",
        "\n",
        "n_train = int(0.9 * len(cifar_dvs))\n",
        "n_test = len(cifar_dvs) - n_train\n",
        "cifar_train, cifar_test = torch.utils.data.random_split(cifar_dvs, [n_train, n_test])\n",
        "\n",
        "cifar_train_loader = DataLoader(cifar_train, batch_size=32, shuffle=True, num_workers=2)\n",
        "cifar_test_loader = DataLoader(cifar_test, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f'CIFAR10-DVS Train: {n_train}, Test: {n_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training on CIFAR10-DVS...')\n",
        "print(f'Device: {device}')\n",
        "\n",
        "cifar_dvs_model = EventSNN(in_channels=2, num_classes=10).to(device)\n",
        "optimizer = optim.Adam(cifar_dvs_model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 30\n",
        "best_cifar_acc = 0\n",
        "cifar_dvs_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(cifar_dvs_model, cifar_train_loader, optimizer, device)\n",
        "    test_acc = evaluate(cifar_dvs_model, cifar_test_loader, device)\n",
        "    \n",
        "    cifar_dvs_history.append(test_acc)\n",
        "    if test_acc > best_cifar_acc:\n",
        "        best_cifar_acc = test_acc\n",
        "        torch.save(cifar_dvs_model.state_dict(), 'best_cifar10_dvs.pth')\n",
        "    \n",
        "    print(f'Epoch {epoch+1:2d}/{EPOCHS} | Train: {train_acc:.2f}% | Test: {test_acc:.2f}% | Best: {best_cifar_acc:.2f}%')\n",
        "\n",
        "print(f'\\nCIFAR10-DVS Best Accuracy: {best_cifar_acc:.2f}% (SOTA: ~83%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('=' * 60)\n",
        "print('NEUROMORPHIC BENCHMARK RESULTS')\n",
        "print('=' * 60)\n",
        "print(f'{\"Dataset\":<15} {\"Our Acc\":<12} {\"SOTA\":<10} {\"Gap\":<10}')\n",
        "print('-' * 60)\n",
        "print(f'{\"N-MNIST\":<15} {best_nmnist_acc:.2f}% {\"~99%\":<10} {best_nmnist_acc - 99:.2f}%')\n",
        "print(f'{\"DVS-Gesture\":<15} {best_dvs_acc:.2f}% {\"~98%\":<10} {best_dvs_acc - 98:.2f}%')\n",
        "print(f'{\"CIFAR10-DVS\":<15} {best_cifar_acc:.2f}% {\"~83%\":<10} {best_cifar_acc - 83:.2f}%')\n",
        "print('=' * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].plot(nmnist_history, 'b-', linewidth=2)\n",
        "axes[0].axhline(y=99, color='r', linestyle='--', label='SOTA ~99%')\n",
        "axes[0].set_title('N-MNIST', fontsize=14)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy (%)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(dvs_history, 'g-', linewidth=2)\n",
        "axes[1].axhline(y=98, color='r', linestyle='--', label='SOTA ~98%')\n",
        "axes[1].set_title('DVS-Gesture', fontsize=14)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(cifar_dvs_history, 'm-', linewidth=2)\n",
        "axes[2].axhline(y=83, color='r', linestyle='--', label='SOTA ~83%')\n",
        "axes[2].set_title('CIFAR10-DVS', fontsize=14)\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('neuromorphic_benchmark.png', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(nmnist_model.state_dict(), '/content/drive/MyDrive/nmnist_model.pth')\n",
        "torch.save(dvs_model.state_dict(), '/content/drive/MyDrive/dvs_gesture_model.pth')\n",
        "torch.save(cifar_dvs_model.state_dict(), '/content/drive/MyDrive/cifar10_dvs_model.pth')\n",
        "\n",
        "print('All models saved to Google Drive!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
